{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T17:50:26.636351Z",
     "iopub.status.busy": "2025-02-06T17:50:26.636038Z",
     "iopub.status.idle": "2025-02-06T17:50:47.833862Z",
     "shell.execute_reply": "2025-02-06T17:50:47.833083Z",
     "shell.execute_reply.started": "2025-02-06T17:50:26.636300Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install \"bayesian-optimization==1.3.1\"  --quiet\n",
    "!pip install lightning  --quiet\n",
    "!pip install scikit-learn torchvision numpy seaborn  --quiet\n",
    "!pip install transformers --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "mp.set_start_method('spawn', force=True)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"  # Adjust based on your system's capability\n",
    "import glob\n",
    "\n",
    "# Then import other libraries and define your code\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, average_precision_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix as ConfusionMatrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import AutoAugment, AutoAugmentPolicy\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.strategies import DDPStrategy\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "from torchmetrics.classification import Accuracy, Precision, Recall, F1Score, MulticlassF1Score\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(in_channels, in_channels // reduction, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(in_channels // reduction, in_channels, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.global_avg_pool(x).view(b, c)\n",
    "        y = self.fc1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.sigmoid(y).view(b, c, 1, 1)\n",
    "        return x * y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T17:50:47.841238Z",
     "iopub.status.busy": "2025-02-06T17:50:47.840879Z",
     "iopub.status.idle": "2025-02-06T17:50:47.862649Z",
     "shell.execute_reply": "2025-02-06T17:50:47.861909Z",
     "shell.execute_reply.started": "2025-02-06T17:50:47.841159Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResNetWrapper(pl.LightningModule):\n",
    "    def __init__(self, lr, sigmoid_threshold=0.5, dropout_rate = 0.5):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.dropout_rate   = dropout_rate  \n",
    "        self.sigmoid_threshold = sigmoid_threshold\n",
    "        self.validation_step_y_hats = []\n",
    "        self.validation_step_ys = []\n",
    "\n",
    "        backbone = timm.create_model('seresnet152d', pretrained=True, num_classes=80)\n",
    "        layers = list(backbone.children())[:-1]  # Remove the final fully connected layer\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        layers.insert(-1, SEBlock(in_channels=2048))  # 2048 az utolsó réteg csatornáinak száma ResNet50 esetén\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(self.dropout_rate), # hyperparameter\n",
    "            nn.Linear(backbone.fc.in_features, out_features=80)\n",
    "        )\n",
    "        \n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        self.train_acc = Accuracy(task=\"multilabel\",num_labels=80)\n",
    "        self.val_acc = Accuracy(task=\"multilabel\",num_labels=80)\n",
    "        self.train_precision = Precision(task=\"multilabel\",num_labels=80)\n",
    "        self.val_precision = Precision(task=\"multilabel\",num_labels=80)\n",
    "        self.train_recall = Recall(task=\"multilabel\",num_labels=80)\n",
    "        self.val_recall = Recall(task=\"multilabel\",num_labels=80)\n",
    "        self.train_f1 = F1Score(task=\"multilabel\",num_labels=80)\n",
    "        self.val_f1 = F1Score(task=\"multilabel\",num_labels=80)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x) \n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        preds = torch.sigmoid(logits) > self.sigmoid_threshold\n",
    "\n",
    "        # Update metrics\n",
    "        self.train_acc.update(preds, y)\n",
    "        self.train_precision.update(preds, y)\n",
    "        self.train_recall.update(preds, y)\n",
    "        self.train_f1.update(preds, y)\n",
    "        self.log('train_acc', self.train_acc)\n",
    "        self.log('train_precision', self.train_precision)\n",
    "        self.log('train_recall', self.train_recall)\n",
    "        self.log('train_f1', self.train_f1)\n",
    "        \n",
    "        return loss\n",
    "    def on_train_epoch_end(self):\n",
    "        # Reset training metrics at the end of the epoch\n",
    "        self.train_acc.reset()\n",
    "        self.train_precision.reset()\n",
    "        self.train_recall.reset()\n",
    "        self.train_f1.reset()\n",
    "\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        \n",
    "        preds = torch.sigmoid(logits) > self.sigmoid_threshold\n",
    "        self.val_acc.update(preds, y)\n",
    "        self.val_precision.update(preds, y)\n",
    "        self.val_recall.update(preds, y)\n",
    "        self.val_f1.update(preds, y)\n",
    "    \n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True, on_step=False)\n",
    "        return {\"val_loss\": loss}\n",
    "    \n",
    "\n",
    "            \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        preds = torch.sigmoid(logits) > self.sigmoid_threshold\n",
    "    \n",
    "        self.log(\"test_preds\", preds)\n",
    "        self.log(\"test_targets\", y)\n",
    "\n",
    "    \n",
    "        self.validation_step_y_hats.append(preds.cpu())\n",
    "        self.validation_step_ys.append(y.cpu())\n",
    "        return {'preds': preds, 'targets': y}\n",
    "\n",
    "        \n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log('val_acc', self.val_acc.compute(), on_epoch=True, prog_bar=True)\n",
    "        self.log('val_precision', self.val_precision.compute(), on_epoch=True, prog_bar=True)\n",
    "        self.log('val_recall', self.val_recall.compute(), on_epoch=True, prog_bar=True)\n",
    "        self.log('val_f1', self.val_f1.compute(), on_epoch=True, prog_bar=True)\n",
    "        self.val_acc.reset()\n",
    "        self.val_precision.reset()\n",
    "        self.val_recall.reset()\n",
    "        self.val_f1.reset()\n",
    "\n",
    "\n",
    "    def on_epoch_start(self):\n",
    "        current_lr = self.optimizers().param_groups[0]['lr']\n",
    "        self.log('lr', current_lr, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        # Total number of training steps (epochs * steps_per_epoch)\n",
    "        total_training_steps = (\n",
    "            len(self.trainer.datamodule.train_dataloader()) // self.trainer.world_size\n",
    "        ) * self.trainer.max_epochs\n",
    "        warmup_steps = int(0.1 * total_training_steps)  # 10% of total steps for warmup\n",
    "        \n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer, \n",
    "            num_warmup_steps=warmup_steps, \n",
    "            num_training_steps=total_training_steps\n",
    "        )\n",
    "        return [optimizer], [{\"scheduler\": scheduler, \"interval\": \"step\"}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best threshold: 0.3527\n",
    "Best validation loss: 0.0591"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T17:50:47.864645Z",
     "iopub.status.busy": "2025-02-06T17:50:47.864451Z",
     "iopub.status.idle": "2025-02-06T17:50:47.883824Z",
     "shell.execute_reply": "2025-02-06T17:50:47.883072Z",
     "shell.execute_reply.started": "2025-02-06T17:50:47.864629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def target_to_oh(target):\n",
    "    NUM_CLASSES = 80  # Number of classes\n",
    "    one_hot = torch.zeros(NUM_CLASSES)  # Create a tensor of zeros with shape (NUM_CLASSES,)\n",
    "    one_hot[target] = 1  # Set the correct class index to 1\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_train_test_split_proportional(dataset, test_ratio=0.1, seed=42, transform=None):\n",
    "    \"\"\"\n",
    "    Create a train-test split proportional to the dataset's labels.\n",
    "\n",
    "    Args:\n",
    "        dataset (ImageFolder): The dataset to split.\n",
    "        test_ratio (float): Proportion of the dataset to include in the test split.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "        transform: Image transformation for preprocessing.\n",
    "\n",
    "    Returns:\n",
    "        train_dataset, test_dataset, idx_to_label: The train/test split datasets and label mapping.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Group samples by label\n",
    "    label_to_samples = defaultdict(list)\n",
    "    for sample in dataset.samples:\n",
    "        label_to_samples[sample[1]].append(sample)\n",
    "\n",
    "    train_samples = []\n",
    "    test_samples = []\n",
    "\n",
    "    # Split the dataset into train and test samples\n",
    "    for label, samples in label_to_samples.items():\n",
    "        random.shuffle(samples)\n",
    "        num_test = int(len(samples) * test_ratio)\n",
    "        test_samples.extend(samples[:num_test])\n",
    "        train_samples.extend(samples[num_test:])\n",
    "\n",
    "    # Create ImageFolder datasets for train and test\n",
    "    train_dataset = ImageFolder(dataset.root, transform=transform)\n",
    "    train_dataset.samples = train_samples\n",
    "    train_dataset.targets = [sample[1] for sample in train_samples]  # Update targets\n",
    "\n",
    "    test_dataset = ImageFolder(dataset.root, transform=transform)\n",
    "    test_dataset.samples = test_samples\n",
    "    test_dataset.targets = [sample[1] for sample in test_samples]  # Update targets\n",
    "\n",
    "    # Use the class_to_idx from the original dataset for label mapping\n",
    "    idx_to_label = {v: k for k, v in dataset.class_to_idx.items()}\n",
    "\n",
    "    return train_dataset, test_dataset, idx_to_label\n",
    "\n",
    "\n",
    "class MyDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_data, val_data, test_dataset = None, batch_size=32, num_workers=4, persistent_workers=True):\n",
    "        super().__init__()\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.persistent_workers = persistent_workers\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset_with_transform = [(x, target_to_oh(y)) for x, y in self.train_data]\n",
    "  \n",
    "        train_loader = DataLoader(train_dataset_with_transform, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers, persistent_workers = self.persistent_workers)\n",
    "     \n",
    "        return train_loader\n",
    "\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset_with_transform = [(x, target_to_oh(y)) for x, y in self.val_data]\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "                    val_dataset_with_transform, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, persistent_workers = self.persistent_workers)\n",
    "\n",
    "        return val_loader        \n",
    "    def test_dataloader(self):\n",
    "        test_dataset_with_transform = [(x, target_to_oh(y)) for x, y in self.test_data]\n",
    "        return DataLoader(test_dataset_with_transform, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, persistent_workers = self.persistent_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T17:50:47.884934Z",
     "iopub.status.busy": "2025-02-06T17:50:47.884653Z",
     "iopub.status.idle": "2025-02-06T17:51:06.078099Z",
     "shell.execute_reply": "2025-02-06T17:51:06.077261Z",
     "shell.execute_reply.started": "2025-02-06T17:50:47.884907Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 10000\n",
      "\n",
      "Train dataset size: 9200\n",
      "Test dataset size: 800 \n",
      "\n",
      "Unique class indices in dataset: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79} \n",
      "\n",
      "Number of unique classes: 80 \n",
      "\n",
      "Train label distribution: Counter({0: 115, 1: 115, 2: 115, 3: 115, 4: 115, 5: 115, 6: 115, 7: 115, 8: 115, 9: 115, 10: 115, 11: 115, 12: 115, 13: 115, 14: 115, 15: 115, 16: 115, 17: 115, 18: 115, 19: 115, 20: 115, 21: 115, 22: 115, 23: 115, 24: 115, 25: 115, 26: 115, 27: 115, 28: 115, 29: 115, 30: 115, 31: 115, 32: 115, 33: 115, 34: 115, 35: 115, 36: 115, 37: 115, 38: 115, 39: 115, 40: 115, 41: 115, 42: 115, 43: 115, 44: 115, 45: 115, 46: 115, 47: 115, 48: 115, 49: 115, 50: 115, 51: 115, 52: 115, 53: 115, 54: 115, 55: 115, 56: 115, 57: 115, 58: 115, 59: 115, 60: 115, 61: 115, 62: 115, 63: 115, 64: 115, 65: 115, 66: 115, 67: 115, 68: 115, 69: 115, 70: 115, 71: 115, 72: 115, 73: 115, 74: 115, 75: 115, 76: 115, 77: 115, 78: 115, 79: 115}) \n",
      "\n",
      "Test label distribution: Counter({0: 10, 1: 10, 2: 10, 3: 10, 4: 10, 5: 10, 6: 10, 7: 10, 8: 10, 9: 10, 10: 10, 11: 10, 12: 10, 13: 10, 14: 10, 15: 10, 16: 10, 17: 10, 18: 10, 19: 10, 20: 10, 21: 10, 22: 10, 23: 10, 24: 10, 25: 10, 26: 10, 27: 10, 28: 10, 29: 10, 30: 10, 31: 10, 32: 10, 33: 10, 34: 10, 35: 10, 36: 10, 37: 10, 38: 10, 39: 10, 40: 10, 41: 10, 42: 10, 43: 10, 44: 10, 45: 10, 46: 10, 47: 10, 48: 10, 49: 10, 50: 10, 51: 10, 52: 10, 53: 10, 54: 10, 55: 10, 56: 10, 57: 10, 58: 10, 59: 10, 60: 10, 61: 10, 62: 10, 63: 10, 64: 10, 65: 10, 66: 10, 67: 10, 68: 10, 69: 10, 70: 10, 71: 10, 72: 10, 73: 10, 74: 10, 75: 10, 76: 10, 77: 10, 78: 10, 79: 10}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([ \n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.TrivialAugmentWide(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Apply exclusions\n",
    "dataset = ImageFolder('/kaggle/input/25dataset/125images', transform=None)\n",
    "print(f\"Original dataset size: {len(dataset)}\")\n",
    "\n",
    "\n",
    "# Create the train-test split and update label mapping\n",
    "train_dataset, test_dataset, idx_to_label = create_train_test_split_proportional(dataset, test_ratio=0.08, seed=42, transform=transform)\n",
    "print()\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\", '\\n')\n",
    "print(\"Unique class indices in dataset:\", set([sample[1] for sample in dataset.samples]), '\\n')\n",
    "print(\"Number of unique classes:\", len(set([sample[1] for sample in dataset.samples])), '\\n')\n",
    "print(\"Train label distribution:\", Counter([sample[1] for sample in train_dataset.samples]), '\\n')\n",
    "print(\"Test label distribution:\", Counter([sample[1] for sample in test_dataset.samples]), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T17:51:06.079392Z",
     "iopub.status.busy": "2025-02-06T17:51:06.079057Z",
     "iopub.status.idle": "2025-02-06T17:51:06.082850Z",
     "shell.execute_reply": "2025-02-06T17:51:06.081999Z",
     "shell.execute_reply.started": "2025-02-06T17:51:06.079367Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lr = 0.007323\n",
    "threshold=0.4796\n",
    "\n",
    "batch_size= 23\n",
    "dropout_rate=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T17:51:06.083956Z",
     "iopub.status.busy": "2025-02-06T17:51:06.083751Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-Fold Cross-Validation:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5b91ed885b4741b208c893d3e1bc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO: Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "INFO: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "INFO: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    }
   ],
   "source": [
    "# KFold Cross-Validation\n",
    "#lr = 0.008274600824983372\n",
    "#threshold = 0.3527\n",
    "\n",
    "# or 0.3395    es batch 51\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)  # 5-fold cross-validation\n",
    "val_losses = []\n",
    "\n",
    "# Assuming you have `train_dataset` defined as an ImageFolder dataset\n",
    "for fold, (train_idx, val_idx) in tqdm(enumerate(kf.split(np.arange(len(train_dataset)))), total=kf.get_n_splits(), desc=\"K-Fold Cross-Validation\"):\n",
    "    print(f\"Fold {fold + 1}/{kf.n_splits}\")\n",
    "\n",
    "\n",
    "    # Split the dataset into train and validation subsets using indices\n",
    "    train_subset = Subset(train_dataset, train_idx)\n",
    "    val_subset = Subset(train_dataset, val_idx)\n",
    "\n",
    "    # Create Data Module for each fold\n",
    "    data_module = MyDataModule(train_subset, val_subset, batch_size, num_workers=1, persistent_workers=True)\n",
    "\n",
    "    # Setup the model for multilabel classification\n",
    "    model = ResNetWrapper(lr=lr, sigmoid_threshold=threshold, dropout_rate=dropout_rate)\n",
    "\n",
    "    # Logger\n",
    "    logger = TensorBoardLogger(\"lightning_logs\", name=f\"multilabel_training_fold_{fold}\")\n",
    "\n",
    "    # ModelCheckpoint to save only the best models (monitor F1 score for multilabel)\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val_f1\",  # Monitor validation F1 score\n",
    "        mode=\"max\",        # Maximize the F1 score\n",
    "        save_top_k=1,      # Save only the best model\n",
    "        filename=\"{epoch}-{val_f1:.4f}\"\n",
    "    )\n",
    "\n",
    "    # EarlyStopping based on F1 score\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"val_f1\",  # Use F1 for stopping\n",
    "        patience=3,        # Stop after 3 non-improving epochs\n",
    "        mode=\"max\"\n",
    "    )\n",
    "\n",
    "    # Setup the Trainer\n",
    "    trainer = Trainer(\n",
    "        fast_dev_run=True,\n",
    "        logger=logger,\n",
    "        max_epochs=30,\n",
    "        devices='auto',  # Adjust based on your hardware\n",
    "        accelerator=\"gpu\",  # Use \"gpu\" or \"tpu\" based on availability\n",
    "        strategy=\"ddp_notebook\",\n",
    "        callbacks=[early_stopping, checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "    # Log validation loss for this fold\n",
    "    val_losses.append(trainer.callback_metrics[\"val_loss\"].item())\n",
    "\n",
    "# After cross-validation, retrieve the best model path\n",
    "best_model_path = checkpoint_callback.best_model_path\n",
    "print(\"Best model saved at:\", best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T16:42:44.260816Z",
     "iopub.status.busy": "2025-01-03T16:42:44.260531Z",
     "iopub.status.idle": "2025-01-03T16:42:44.523653Z",
     "shell.execute_reply": "2025-01-03T16:42:44.522644Z",
     "shell.execute_reply.started": "2025-01-03T16:42:44.260794Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image, label = train_dataset[3]\n",
    "print(idx_to_label.get(image))\n",
    "\n",
    "plt.imshow(image.permute(1, 2, 0))  # A csatornákat (C, H, W) átrendezzük (H, W, C) formátumba\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T18:40:28.313Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install pretty-confusion-matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T15:22:33.052342Z",
     "iopub.status.busy": "2025-01-03T15:22:33.051952Z",
     "iopub.status.idle": "2025-01-03T15:22:33.202639Z",
     "shell.execute_reply": "2025-01-03T15:22:33.201488Z",
     "shell.execute_reply.started": "2025-01-03T15:22:33.052310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!ls /kaggle/working/lightning_logs/multilabel_training_fold_0/version_5/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:20:15.077330Z",
     "iopub.status.busy": "2025-01-30T12:20:15.076957Z",
     "iopub.status.idle": "2025-01-30T12:20:26.872147Z",
     "shell.execute_reply": "2025-01-30T12:20:26.871288Z",
     "shell.execute_reply.started": "2025-01-30T12:20:15.077301Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 211MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f1:  0.6166127229323823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Oracle images': 0.15384615384615383,\n",
       " 'Nissan images': 0.26666666666666666,\n",
       " 'Sony images': 0.28571428571428575,\n",
       " 'UPS images': 0.28571428571428575,\n",
       " 'Toyota images': 0.30769230769230765,\n",
       " 'Netflix images': 0.33333333333333326,\n",
       " 'Cartier images': 0.4,\n",
       " 'Gucci images': 0.4,\n",
       " 'Intel images': 0.4,\n",
       " 'Prada images': 0.4,\n",
       " 'Disney images': 0.4210526315789474,\n",
       " 'Google images': 0.4285714285714285,\n",
       " 'Kia images': 0.4285714285714285,\n",
       " 'Zara images': 0.4285714285714285,\n",
       " 'HP images': 0.4615384615384615,\n",
       " 'Instagram images': 0.4615384615384615,\n",
       " 'Tesla images': 0.47058823529411764,\n",
       " 'Corona images': 0.5,\n",
       " 'Hyundai images': 0.5,\n",
       " 'Danone images': 0.5333333333333333}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, multilabel_confusion_matrix\n",
    "\n",
    "best_model_path=\"/kaggle/working/lightning_logs/multilabel_training_fold_0/version_5/checkpoints/epoch=22-val_loss=0.04.ckpt\"\n",
    "best_model_path=\"lightning_logs/multilabel_training_fold_4/version_10/checkpoints/epoch=17-val_f1=0.6584.ckpt\"\n",
    "best_model_path=\"/kaggle/input/may_be_the_best_resnet/pytorch/default/1/version_10/checkpoints/epoch=17-val_f1=0.6584.ckpt\"\n",
    "best_model = ResNetWrapper.load_from_checkpoint(best_model_path, lr=lr, sigmoid_threshold= threshold, dropout_rate=0.1)\n",
    "\n",
    "mxs = []\n",
    "f1s = []\n",
    "\n",
    "def evaluate_model(model, test_loader, sigmoid_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test data, including confusion matrix and F1 score for each label.\n",
    "    \"\"\"\n",
    "    # Ensure model is on the appropriate device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Iterate through test DataLoader\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            \n",
    "            # Move data to the same device as the model\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            # Sigmoid activation + thresholding\n",
    "            preds = (torch.sigmoid(logits) > sigmoid_threshold).cpu().numpy()\n",
    "            targets = y.cpu().numpy()\n",
    "\n",
    "            # Append batch predictions and targets\n",
    "            all_preds.append(preds)\n",
    "            all_targets.append(targets)\n",
    "\n",
    "    # Concatenate all predictions and targets\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "    # Compute multi-class confusion matrix for all classes\n",
    "    mxs.append(multilabel_confusion_matrix(all_targets, all_preds))\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score for each label\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_preds, average=None, zero_division=0)\n",
    "\n",
    "    for i, f1_score in enumerate(f1):\n",
    "        f1s.append(f1_score)\n",
    "    return f1s\n",
    "\n",
    "# Test the evaluation\n",
    "test_data_module = MyDataModule(train_dataset, train_dataset, test_dataset, batch_size, num_workers=2)\n",
    "test_loader = test_data_module.test_dataloader()\n",
    "f1s = evaluate_model(best_model, test_loader, sigmoid_threshold=threshold)\n",
    "\n",
    "print(f\"Mean f1:  {np.mean(f1s)}\")\n",
    "\n",
    "f1_dict = {}\n",
    "for i, f1 in enumerate(f1s):\n",
    "    label_name = idx_to_label.get(i, f\"Label {i}\")  # Get the label name or default to \"Label i\"\n",
    "    f1_dict[label_name]=f1\n",
    "dict(sorted(f1_dict.items(), key=lambda item: item[1])[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T08:07:24.519362Z",
     "iopub.status.busy": "2025-01-06T08:07:24.519062Z",
     "iopub.status.idle": "2025-01-06T08:07:24.525844Z",
     "shell.execute_reply": "2025-01-06T08:07:24.524972Z",
     "shell.execute_reply.started": "2025-01-06T08:07:24.519336Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dict(sorted(f1_dict.items(), key=lambda item: item[1])[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### last mean f1 score 0.41\n",
    "\n",
    "### new mean f1 score 0.62\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T12:23:23.610107Z",
     "iopub.status.busy": "2025-01-30T12:23:23.609686Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you already have the reverse index mapping: idx_to_label\n",
    "mxs_0 = mxs[0]\n",
    "# Calculate number of rows and columns for the subplots (80 matrices)\n",
    "n_rows = 10  # You can adjust this for different grid sizes\n",
    "n_cols = 8   # Adjusted to fit 80 matrices in a grid\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(24, 16))  # Adjust the size as needed\n",
    "axes = axes.ravel()  # Flatten the axes array to index them easily\n",
    "\n",
    "# Plot each confusion matrix\n",
    "for i, mx in enumerate(mxs_0):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot the heatmap with masked zeros\n",
    "    sns.heatmap(mx, annot=True, fmt='d', vmin=0.5, vmax=1, cbar=False, ax=ax, square=True)\n",
    "    \n",
    "    # Set title with the index and label name\n",
    "    label_name = idx_to_label.get(i, f\"Label {i}\")  # Get the label name or default to \"Label i\"\n",
    "    ax.set_title(f'{label_name} (Index {i})')\n",
    "    ax.set_xlabel('Predicted', fontsize=14)\n",
    "    ax.set_ylabel('Actual', fontsize=14)\n",
    "\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-01-03T16:53:34.714005Z",
     "iopub.status.busy": "2025-01-03T16:53:34.713705Z",
     "iopub.status.idle": "2025-01-03T21:21:42.757195Z",
     "shell.execute_reply": "2025-01-03T21:21:42.755772Z",
     "shell.execute_reply.started": "2025-01-03T16:53:34.713982Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the objective function for Bayesian Optimization\n",
    "def objective(batch_size, dropout_rate):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold cross-validation\n",
    "    val_losses = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(train_dataset)))):\n",
    "        # Split the dataset into train and validation sets\n",
    "        train_subset = torch.utils.data.Subset(train_dataset, train_idx)\n",
    "        val_subset = torch.utils.data.Subset(train_dataset, val_idx)\n",
    "    \n",
    "        # Create Data Module for each fold\n",
    "        data_module = MyDataModule(train_subset, val_subset, batch_size, num_workers=2, persistent_workers=True)\n",
    "        # Setup the model\n",
    "        model = ResNetWrapper(dropout_rate=dropout_rate, lr=0.007323, sigmoid_threshold=0.4796)\n",
    "\n",
    "\n",
    "            # Logger\n",
    "        logger = TensorBoardLogger(\"lightning_logs\", name=f\"multilabel_training_fold_{fold}\")\n",
    "\n",
    "        # ModelCheckpoint to save only the best models\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",  # Minimize the val_loss\n",
    "            save_top_k=1,  # Save only the best model\n",
    "            filename=\"{epoch}-{val_loss:.2f}\"\n",
    "        )\n",
    "\n",
    "        # EarlyStopping based on validation loss\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"val_loss\", \n",
    "            patience=5, \n",
    "            mode=\"min\"\n",
    "        )\n",
    "\n",
    "        # Setup the Trainer\n",
    "        trainer = Trainer(\n",
    "            logger=logger,\n",
    "            max_epochs=30,\n",
    "            accelerator=\"gpu\",  # Use \"gpu\" or \"tpu\" based on availability\n",
    "            callbacks=[early_stopping, checkpoint_callback]\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "        # Get the validation loss (you need to log it properly during validation_step)\n",
    "        if \"val_loss\" in trainer.callback_metrics:\n",
    "            val_loss = trainer.callback_metrics[\"val_loss\"].item()\n",
    "        else:\n",
    "            val_loss = float('inf')  # Or some default high value\n",
    "\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    return -val_loss  # Return negative val_loss to maximize\n",
    "\n",
    "# Define the search space\n",
    "pbounds = {\n",
    "    'batch_size': (16, 64),  # Memória függvényében növelheted 128-ig\n",
    "    'dropout_rate': (0.1, 0.5)\n",
    "}\n",
    "# Initialize Bayesian Optimization\n",
    "optimizer = BayesianOptimization(\n",
    "    f=objective,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Run the optimization\n",
    "optimizer.maximize(\n",
    "    init_points=5,  # Number of initial random evaluations\n",
    "    n_iter=5  # Number of optimization iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-03T09:22:21.842738Z",
     "iopub.status.idle": "2025-01-03T09:22:21.843102Z",
     "shell.execute_reply": "2025-01-03T09:22:21.842938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Print the best parameters\n",
    "best_params = optimizer.max['params']\n",
    "best_params['batch_size'] = int(best_params['batch_size'])\n",
    "print(\"Best parameters: \", best_params)\n",
    " # 0.00732   | 0.4592  val_f1= 0.461\n",
    "# | 0.007323  | 0.4796    val_f1=0.528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T18:40:28.315Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Best threshold: {optimizer.max['params']['threshold']:.4f}\")\n",
    "print(f\"Best validation loss: {-optimizer.max['target']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T14:57:43.807932Z",
     "iopub.status.busy": "2025-01-03T14:57:43.807639Z",
     "iopub.status.idle": "2025-01-03T14:59:18.765581Z",
     "shell.execute_reply": "2025-01-03T14:59:18.764659Z",
     "shell.execute_reply.started": "2025-01-03T14:57:43.807907Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "def download_file(path, download_file_name):\n",
    "    os.chdir('/kaggle/working/')\n",
    "    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n",
    "    command = f\"zip {zip_name} {path} -r\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Unable to run zip command!\")\n",
    "        print(result.stderr)\n",
    "        return\n",
    "    display(FileLink(f'{download_file_name}.zip'))\n",
    "download_file('/kaggle/working/', 'out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T14:59:18.766868Z",
     "iopub.status.busy": "2025-01-03T14:59:18.766631Z",
     "iopub.status.idle": "2025-01-03T14:59:18.916940Z",
     "shell.execute_reply": "2025-01-03T14:59:18.916170Z",
     "shell.execute_reply.started": "2025-01-03T14:59:18.766848Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r file.zip /kaggle/working/lightning_logs/training_proper_test\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'file.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on the labeled logo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T18:40:28.316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!ls lightning_logs/training_proper_test/version_24/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T18:40:28.316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "\n",
    "metric = MulticlassConfusionMatrix(num_classes=5)\n",
    "metric.update(all_labels, all_preds)\n",
    "fig_, ax_ = metric.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T18:40:28.316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "from glob import glob\n",
    "\n",
    "# Assuming your test dataset is set up already\n",
    "batch_size = 23\n",
    "lr = 0.008274600824983372\n",
    "\n",
    "# Create the test DataLoader\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Find all checkpoint files recursively across all versions\n",
    "checkpoint_directory = '/kaggle/working/lightning_logs/multilabel_training_fold_2/'\n",
    "checkpoint_files = glob(os.path.join(checkpoint_directory, '**', '*.ckpt'), recursive=True)\n",
    "\n",
    "# Define a dictionary to store the performance of each checkpoint\n",
    "checkpoint_performance = {}\n",
    "\n",
    "# Iterate through each checkpoint file\n",
    "for checkpoint in checkpoint_files:\n",
    "    # Load the model from checkpoint\n",
    "    model = best_model\n",
    "    model.eval()  \n",
    "    model.to('cuda')\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Evaluate model\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "\n",
    "            # Get model predictions\n",
    "            outputs = model(inputs)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(probabilities, 1)\n",
    "\n",
    "            # Store predictions and labels\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Update accuracy\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    # Calculate F1 score and accuracy\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # Store the performance metrics for the current checkpoint\n",
    "    checkpoint_performance[checkpoint] = {'f1_score': f1, 'accuracy': accuracy}\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Checkpoint: {checkpoint}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\\n\")\n",
    "\n",
    "# Find the best checkpoint based on F1 score\n",
    "best_checkpoint = max(checkpoint_performance, key=lambda x: checkpoint_performance[x]['f1_score'])\n",
    "best_f1_score = checkpoint_performance[best_checkpoint]['f1_score']\n",
    "best_accuracy = checkpoint_performance[best_checkpoint]['accuracy']\n",
    "\n",
    "print(\"\\nBest Checkpoint:\")\n",
    "print(f\"Path: {best_checkpoint}\")\n",
    "print(f\"F1 Score: {best_f1_score:.4f}\")\n",
    "print(f\"Accuracy: {best_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T18:40:28.316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Function to unnormalize images for display\n",
    "def unnormalize(img_tensor, mean, std):\n",
    "    img_tensor = img_tensor.clone()  # Clone the tensor to avoid modifying the original\n",
    "    for t, m, s in zip(img_tensor, mean, std):\n",
    "        t.mul_(s).add_(m)  # Unnormalize each channel\n",
    "    return img_tensor\n",
    "\n",
    "# Define mean and std from your transform for unnormalizing\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Create a function to plot a grid of images\n",
    "def plot_image_grid(dataset, num_images=16):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(8, 8))  # Grid of 4x4 for 16 images\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(num_images):\n",
    "        img, label = dataset[i]\n",
    "        img = unnormalize(img, mean, std)  # Unnormalize\n",
    "        img = img.permute(1, 2, 0).numpy()  # Convert from CxHxW to HxWxC\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Label: {label}\")\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some images from the training dataset\n",
    "plot_image_grid(test_set, num_images=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T18:40:28.316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "# Define the threshold for classification\n",
    "threshold = 0.8\n",
    "batch_size = 23\n",
    "lr = 0.008274600824983372\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = Trainer()\n",
    "\n",
    "results = []\n",
    "checkpoint = \"/kaggle/input/checkpoints/lightning_logs/the training/version_4/checkpoints/epoch=8-val_loss=1.39.ckpt\"\n",
    "\n",
    "# Load the test dataset\n",
    "test_dataset = ImageFolder(root='/kaggle/input/brand-logos/test', transform=transform)\n",
    "\n",
    "# Create the test DataLoader\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Load the model from the checkpoint\n",
    "model = ResNetWrapper.load_from_checkpoint(checkpoint, lr=lr, num_classes=100, \n",
    "                                            backbone_weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "print(isinstance(model, LightningModule))\n",
    "model.eval()  # Set model to evaluation mode if necessary\n",
    "\n",
    "# Test the model using the Trainer\n",
    "test_results = trainer.test(model, test_loader)\n",
    "\n",
    "# Process the test results to compute thresholds if needed\n",
    "preds = test_results[0]['preds']\n",
    "labels = test_results[0]['labels']\n",
    "\n",
    "# Convert logits to probabilities and apply thresholding\n",
    "probabilities = F.softmax(preds, dim=1)\n",
    "predicted = (probabilities > threshold).long().max(dim=1)[1]\n",
    "\n",
    "# Store results\n",
    "accuracy = (predicted == labels).sum().item() / len(labels)\n",
    "results.append({'checkpoint': checkpoint, 'accuracy': accuracy})\n",
    "\n",
    "# Output all results\n",
    "for result in results:\n",
    "    print(f\"Checkpoint: {result['checkpoint']} - Accuracy: {result['accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T18:40:28.316Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "overall_f1_macro = f1_score(all_labels, all_preds, average='macro')   # Macro-average\n",
    "print(overall_f1_macro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T18:40:28.316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "!ls /kaggle/working/checkpoints/lightning_logs/\n",
    "!ls /kaggle/working/checkpoints/lightning_logs/version_6/checkpoints\n",
    "!zip -r nyertes.zip /kaggle/working/checkpoints/lightning_logs/version_13/checkpoints/epoch=14-step=2190.ckpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T18:40:28.317Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r version_5.zip /kaggle/working/checkpoints/lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T18:40:28.317Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -U ipywidgets\n",
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T18:40:28.317Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on unlabeled marketing memes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "execution_failed": "2025-01-02T18:40:28.317Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "# Define your brand names in the order they appear in your list\n",
    "brand_names = [\n",
    "    \"3m\", \"axa\", \"accenture\", \"adobe\", \"airbnb\", \"allianz\", \"amazon\", \"americanexpress\", \n",
    "    \"apple\", \"audi\", \"bmw\", \"budweiser\", \"burberry\", \"canon\", \"cartier\", \"caterpillar\", \n",
    "    \"chanel\", \"cisco\", \"citi bank\", \"cocacola\", \"colgate\", \"corona\", \"dhl\", \"danone\", \n",
    "    \"dior\", \"disney\", \"facebook\", \"fedex\", \"ferrari\", \"ford\", \"ge\", \"gillette\", \n",
    "    \"goldmansachs\", \"google\", \"gucci\", \"hm\", \"hp\", \"hsbc\", \"heineken\", \"hennessy\", \n",
    "    \"hermès\", \"hewlettpackardenterprise\", \"honda\", \"huawei\", \"hyundai\", \"ibm\", \"ikea\", \n",
    "    \"instagram\", \"intel\", \"jpmorgan\", \"jackdaniels\", \"johnsonjohnson\", \"kfc\", \"kelloggs\", \n",
    "    \"kia\", \"lego\", \"loréalparis\", \"linkedin\", \"louisvuitton\", \"mastercard\", \"mcdonalds\", \n",
    "    \"mercedesbenz\", \"microsoft\", \"morganstanley\", \"nescafé\", \"nespresso\", \"nestlé\", \n",
    "    \"netflix\", \"nike\", \"nintendo\", \"nissan\", \"oracle\", \"pampers\", \"panasonic\", \"paypal\", \n",
    "    \"pepsi\", \"philips\", \"porsche\", \"prada\", \"redbull\", \"sap\", \"salesforce\", \"samsung\", \n",
    "    \"santander\", \"sephora\", \"siemens\", \"sony\", \"spotify\", \"starbucks\", \"tesla\", \n",
    "    \"tiffanyco\", \"toyota\", \"ups\", \"visa\", \"volkswagen\", \"xiaomi\", \"youtube\", \"zara\", \n",
    "    \"adidas\", \"ebay\"\n",
    "]\n",
    "\n",
    "class UnlabeledImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_paths = [os.path.join(image_dir, img) for img in os.listdir(image_dir) if img.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path\n",
    "\n",
    "\n",
    "# Load the model checkpoint\n",
    "num_classes = 100  # Adjust based on your actual number of classes\n",
    "model = ResNetWrapper.load_from_checkpoint(checkpoint,lr=lr, num_classes=num_classes, backbone_weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# Move the model to the GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet50 typically takes 224x224 input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Define the prediction function\n",
    "def classify_images(model, image_folder, transform, device):\n",
    "    dataset = UnlabeledImageDataset(image_folder, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "    results = {}  # Ensure 'results' dictionary is initialized\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, img_paths in dataloader:\n",
    "            images = images.to(device)\n",
    "            logits = model(images)\n",
    "            probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "            confidences, preds = torch.max(probs, dim=1)  # Get the highest probability and its index for each prediction\n",
    "\n",
    "            for confidence, pred, img_path in zip(confidences, preds, img_paths):\n",
    "                if confidence.item() >= 0.9:  # Only consider predictions with confidence >= 80%\n",
    "                    brand = brand_names[pred.item()].lower()  # Map index to brand name\n",
    "\n",
    "                    if brand not in results:\n",
    "                        results[brand] = []\n",
    "                    results[brand].append(os.path.basename(img_path))  # Append the filename, not the full path\n",
    "\n",
    "    return results\n",
    "\n",
    "# Define the folder containing images to classify\n",
    "image_folder = \"/kaggle/input/5memes-for-top-100-most-valuable-brand-2023\"\n",
    "\n",
    "# Classify images and store the results in a dictionary\n",
    "dict1 = classify_images(model, image_folder, transform, device)\n",
    "\n",
    "\n",
    "# Classify images and store the results in a dictionary\n",
    "dict1 = classify_images(model, image_folder, transform, device)\n",
    "dict2 = {'apple': ['Xiaomi memes_9daf00f7-8607-4ff6-b8e1-1dd5c755f43a.jpeg', 'Apple memes_iphone-chatgpt.jpg', 'Apple memes_Image_2.jpg', 'Huawei memes_Image_3.jpg'], 'microsoft': ['Microsoft memes_Image_5.jpg', 'Microsoft memes_Image_1.jpeg', 'Microsoft memes_Image_4.jpeg', 'HP memes_190d521ac62eaf40a74e50ab39635231.jpg'], 'amazon': ['Amazon memes_Image_1.jpg', 'Amazon memes_Image_2.jpg', 'Amazon memes_Image_4.jpeg', 'Amazon memes_Image_5.jpg', 'Amazon memes_Image_3.jpg'], 'google': ['Google memes_Image_2.jpeg', 'Google memes_Image_1.jpg', 'Xiaomi memes_Image_2.jpeg', 'Google memes_Image_4.jpg', 'Google memes_Image_3.jpg'], 'samsung': ['Samsung memes_Image_1.jpeg', 'Samsung memes_Image_2.jpg', 'Samsung memes_Image_3.jpg', 'Samsung memes_Image_4.jpg', 'Samsung memes_Image_5.jpeg'], 'toyota': ['Toyota memes_Image_1.jpg', 'Toyota memes_Image_2.jpg', 'Toyota memes_Image_4.jpg'], 'mercedes-benz': ['MercedesBenz memes_Image_5.jpg', 'MercedesBenz memes_Image_3.jpg'], 'coca-cola': ['CocaCola memes_Image_2.jpeg', 'Pepsi memes_Image_3.jpg', 'CocaCola memes_Image_1.jpg'], 'nike': [], 'bmw': ['BMW memes_ayNdM3q_460s.jpg', 'BMW memes_Image_4.jpg', 'Audi memes_Image_5.jpg', 'MercedesBenz memes_Image_1.jpg'], \"mcdonald's\": ['McDonalds memes_Image_2.jpg', 'McDonalds memes_Image_1.jpg', 'McDonalds memes_Image_2 (copy 1).jpg'], 'tesla': ['Tesla memes_Image_2.jpg', 'Tesla memes_teslamemes-191110030713-thumbnail.webp', 'Caterpillar memes_image-1.webp', 'Tesla memes_Image_5.jpg'], 'disney': ['Disney memes_Image_1.png', 'Disney memes_Image_2.jpg', 'Disney memes_relatable-disney-memes.png'], 'louis vuitton': ['LouisVuitton memes_Image_1.jpg', 'LouisVuitton memes_tgeycyn3z4k91.jpg', 'LouisVuitton memes_0a2163e267c3e9c175e7c08bf8253318.jpg', 'LouisVuitton memes_Image_2.jpg'], 'cisco': ['Cisco memes_d77c72918e7440d37fc3eabc307ad8ac3a8025383ea34cdb6e1df27c047628f6_1.jpg', 'Cisco memes_Image_3.jpg', 'Cisco memes_Image_1.jpg', 'Cisco memes_fc0j9uamxd371.png'], 'instagram': ['Instagram memes_Image_4.jpg', 'Instagram memes_ig.jpg', 'Heineken memes_Image_1.jpg', 'Instagram memes_Image_5.jpg', 'Airbnb memes_Image_1.jpg', 'Instagram memes_person-women-on-instagram-be-like-got-new-shoes.jpeg', 'Instagram memes_Image_2.jpg', 'HewlettPackardEnterprise memes_EPo6d7mUYAAHsU0.jpg'], 'adobe': ['Adobe memes_Image_3.jpeg', 'Adobe memes_Image_1.jpeg', 'Adobe memes_Image_2.jpeg'], 'ibm': ['IBM memes_Image_2.jpg', 'IBM memes_Image_1.jpg', 'IBM memes_Image_3.jpg'], 'oracle': ['Oracle memes_EXT38P1WkAAjs_5.jpg', 'Oracle memes_Image_5.jpg', 'Oracle memes_programmerhumor-io-databases-memes-backend-memes-ce04a4d894b6035-608x613.webp'], 'sap': ['SAP memes_Image_1.jpeg', 'SAP memes_Image_3.jpg', 'SAP memes_Image_5.png', 'SAP memes_Image_2.jpeg', 'SAP memes_Image_4.jpg'], 'facebook': ['Instagram memes_Image_4.jpg', 'Heineken memes_Image_1.jpg', 'Caterpillar memes_Bj9v-r7IUAApml9.png', 'Facebook memes_Image_1.jpg', 'Facebook memes_Screenshot2021-11-01at16.29.20.jpg', 'TiffanyCo memes_98facae07556bfaab7cb6672371ff06c.jpg', 'Facebook memes_f.jpg', 'Facebook memes_Image_4.jpg', 'HewlettPackardEnterprise memes_EPo6d7mUYAAHsU0.jpg'], 'chanel': ['Chanel memes_images (1).jpeg', 'Chanel memes_Screen-Shot-2021-04-29-at-8.webp', 'Chanel memes_Image_2.jpg', 'Chanel memes_images.jpeg'], 'hermes': ['Herms memes_434053634_18427064311043375_1898595488137274113_n.jpg', 'Herms memes_Fd_gt0bUUAAeCRh.jpg'], 'intel': ['Intel memes_Image_4 (copy 1).jpeg', 'Intel memes_Image_2.jpg', 'Intel memes_Image_4.jpeg', 'Intel memes_Image_1.jpg'], 'youtube': ['YouTube memes_Image_2.jpg', 'YouTube memes_Image_3.jpg'], 'j.p. morgan': ['JPMorgan memes_xq0z4545oqe41.webp', 'MorganStanley memes_Image_1.jpg'], 'honda': ['Honda memes_Image_4.jpg', 'Honda memes_Image_5.jpg'], 'american express': ['AmericanExpress memes_Image_3.jpg', 'AmericanExpress memes_Image_4.jpg', 'AmericanExpress memes_Image_1.jpg'], 'ikea': ['IKEA memes_Image_3.jpg', 'IKEA memes_Image_5.png', 'IKEA memes_Image_2.jpg', 'IKEA memes_Image_4.jpg'], 'accenture': ['Accenture memes_Image_4.jpg', 'Accenture memes_Image_1.png', 'Accenture memes_Image_2.jpg', 'Accenture memes_Image_5.jpg'], 'allianz': ['Allianz memes_amLOMzj_460s.jpg', 'Allianz memes_Image_2.jpg', 'Allianz memes_Image_1.jpg', 'Allianz memes_images.jpeg'], 'hyundai': ['Hyundai memes_Image_3.jpeg', 'Hyundai memes_Image_4.jpg'], 'ups': ['Cisco memes_d77c72918e7440d37fc3eabc307ad8ac3a8025383ea34cdb6e1df27c047628f6_1.jpg', 'UPS memes_Image_4.jpg', 'Ferrari memes_Image_2.jpg', 'DHL memes_Image_2.jpeg', 'UPS memes_Image_3.jpeg', 'UPS memes_Image_2.jpeg'], 'gucci': ['Gucci memes_Image_3.jpg', 'Gucci memes_Image_1.jpg', 'Gucci memes_Image_2 (copy 1).jpg', 'Gucci memes_Image_2.jpg'], 'pepsi': ['Pepsi memes_Image_2.jpeg', 'Pepsi memes_Image_3.jpg', 'Pepsi memes_Image_5.jpeg'], 'sony': ['Sony memes_Image_2.jpg', 'Sony memes_Image_3.jpeg', 'Sony memes_Image_2 (copy 1).jpg', 'Sony memes_Image_1.jpeg'], 'visa': ['Visa memes_Image_3.jpg', 'AmericanExpress memes_Image_2.jpg', 'Visa memes_Image_2.jpg', 'Visa memes_Image_5.jpg', 'Visa memes_Image_4.jpg'], 'salesforce': ['Salesforce memes_Image_1.jpeg', 'Salesforce memes_Image_3.jpeg', 'Salesforce memes_Image_5.jpeg', 'Salesforce memes_Image_2.jpeg', 'Salesforce memes_Image_4.jpg'], 'netflix': ['Netflix memes_Image_4.jpg', 'Cisco memes_d77c72918e7440d37fc3eabc307ad8ac3a8025383ea34cdb6e1df27c047628f6_1.jpg', 'Netflix memes_Image_5.jpg', 'Netflix memes_Image_1.jpg'], 'paypal': ['PayPal memes_Image_4.jpeg', 'PayPal memes_Image_2.jpg', 'PayPal memes_Image_3.jpeg', 'PayPal memes_Image_1.jpeg'], 'mastercard': ['Mastercard memes_Image_2.jpg', 'Mastercard memes_Image_4.jpg', 'Mastercard memes_Image_1.jpeg', 'AmericanExpress memes_Image_2.jpg', 'Visa memes_Image_5.jpg'], 'adidas': ['adidas memes_Image_1.jpeg'], 'zara': ['Zara memes_Image_1.jpeg', 'Zara memes_Image_3.jpeg', 'Zara memes_Image_5.jpg'], 'axa': ['AXA memes_gettyimages-1226469012-612x612.jpg'], 'audi': ['Audi memes_Image_5.jpg', 'MercedesBenz memes_Image_1.jpg', 'Audi memes_Image_4.jpg'], 'airbnb': ['Airbnb memes_Image_3.png', 'Airbnb memes_Image_1.jpg', 'Airbnb memes_Image_4.jpeg', 'Airbnb memes_Image_2.jpg', 'Airbnb memes_P4BwmWt.jpg'], 'porsche': ['Porsche memes_Image_2.jpeg', 'Porsche memes_Image_1.jpg', 'Porsche memes_Image_4.jpg'], 'starbucks': ['Starbucks memes_Image_4.jpg', 'Starbucks memes_Image_2.png', 'Starbucks memes_4e59a310d37f67cbb82bcd067ee4e0c7.jpg', 'Starbucks memes_Image_3.png'], 'ge': ['GE memes_images (2).jpeg'], 'volkswagen': ['Volkswagen memes_Image_3.jpg', 'Volkswagen memes_Image_1.jpeg'], 'ford': ['Ford memes_Image_5.jpeg'], 'nescafé': [], 'siemens': ['Siemens memes_Image_5.jpg', 'Siemens memes_siemens-heh-heh-heh-v0-yf2fbabx814b1.webp', 'Siemens memes_Image_4.jpg', 'Siemens memes_A6Db4nQCQAEw2Xg.jpg'], 'goldman sachs': ['GoldmanSachs memes_Image_5.jpg', 'GoldmanSachs memes_Image_2.jpg', 'GoldmanSachs memes_Image_3.jpg', 'GoldmanSachs memes_Image_4.jpg'], 'pampers': ['Pampers memes_Image_3.jpg', 'Pampers memes_Image_5 (copy 1).jpg', 'Pampers memes_Image_5.jpg'], 'h&m': ['HM memes_tandem-x-visuals-FZOOxR2auVI-unsplash-1313x900.webp', 'HM memes_Image_4.jpeg'], 'l’oréal paris': ['LOralParis memes_Image_3.jpg', 'LOralParis memes_Image_1.jpg', 'LOralParis memes_Image_2.jpeg'], 'citi': ['Cisco memes_d77c72918e7440d37fc3eabc307ad8ac3a8025383ea34cdb6e1df27c047628f6_1.jpg', 'Citi Bank memes_Image_4.jpg', 'MorganStanley memes_Image_3.jpg', 'Citi Bank memes_citi.jpg', 'Citi Bank memes_Image_2.jpg', 'Citi Bank memes_Image_5.jpg'], 'lego': ['LEGO memes_Image_5.jpg', 'LEGO memes_images.jpeg', 'LEGO memes_Image_4.jpeg'], 'red bull': ['JackDaniels memes_Image_2.jpg', 'RedBull memes_Image_5.jpg', 'RedBull memes_Image_2.jpg', 'RedBull memes_Image_4.jpeg', 'RedBull memes_Image_3.jpg'], 'budweiser': ['Budweiser memes_Image_3.jpg', 'Budweiser memes_aoKL853_460s.jpg', 'Budweiser memes_Image_2.jpg', 'Budweiser memes_Image_4.jpg', 'Budweiser memes_Image_1.jpg'], 'ebay': ['eBay memes_Image_4.jpg', 'eBay memes_Image_2.jpg'], 'nissan': ['Nissan memes_Image_2.jpeg', 'Nissan memes_Image_4.jpg', 'Nissan memes_Image_3.jpeg', 'Nissan memes_Image_3.jpg'], 'hp': ['HewlettPackardEnterprise memes_k8m3z.jpg', 'HP memes_38ef2b77327f4020f04dc14dc41f1538.jpg', 'HP memes_190d521ac62eaf40a74e50ab39635231.jpg'], 'hsbc': ['HSBC memes_Image_1.jpg', 'HSBC memes_Image_3.jpg', 'HSBC memes_images.jpeg'], 'morgan stanley': ['MorganStanley memes_4521ccf691de4bacef41ccbb143387b2.jpg', 'MorganStanley memes_Image_4.jpg', 'MorganStanley memes_images.jpeg', 'MorganStanley memes_Image_1.jpg'], 'nestle': ['Nestl memes_Image_1.jpeg', 'Nestl memes_Image_2.jpeg', 'Nestl memes_Image_3.jpeg', 'Nestl memes_Image_4.jpeg', 'Nestl memes_Image_5.jpg'], 'philips': ['Philips memes_Image_4.jpeg', 'Philips memes_images.jpeg', 'Philips memes_Philips-Innovationandyou-1002x1417.jpg', 'Philips memes_unnamed.jpg'], 'spotify': ['Spotify memes_spotify-now-listen-most-boring-pop-charts-yes-hey-xx-xx-tap-banner-now-last-ad-just-two-songs-ago.png', 'Spotify memes_Image_5.jpeg'], 'ferrari': ['Ferrari memes_Image_5.jpg', 'Ferrari memes_Image_1.jpg', 'Ferrari memes_Image_1.jpeg', 'Ferrari memes_Image_2.jpg', 'Ferrari memes_Image_3.png'], 'nintendo': ['Philips memes_Image_4.jpeg', 'Nintendo memes_Image_5.jpeg', 'Nintendo memes_Image_4.jpeg', 'Panasonic memes_Image_3.jpeg'], 'gillette': ['Gillette memes_Image_1.jpeg', 'Gillette memes_Image_2.jpg', 'Gillette memes_Image_4.jpeg', 'Gillette memes_Image_5.jpg'], 'colgate': ['Colgate memes_Image_4.jpeg', 'Colgate memes_Image_2.jpg', 'LOralParis memes_Image_2.jpeg'], 'cartier': ['Cartier memes_CaGpc-1VIAAOpWc.png', 'Cartier memes_Image_3.jpg', 'Cartier memes_Image_1.jpeg', 'Cartier memes_65c080cea63c4.jpeg'], '3m': ['3M memes_Image_2.jpg', '3M memes_Image_5.jpg', '3M memes_Image_3.jpg', '3M memes_khkn86l1vgs41.webp'], 'dior': ['Dior memes_Image_3.jpg', 'Dior memes_Image_5.jpg', 'Dior memes_Image_2.jpg', 'Dior memes_Image_4.jpeg', 'Dior memes_Image_4.jpg'], 'santander': ['Santander memes_Image_2.jpg', 'Santander memes_Image_3.jpg', 'Santander memes_Image_4.jpg', 'Santander memes_meme1.webp'], 'danone': ['Danone memes_Image_2.jpg', 'Danone memes_Image_3.jpg', 'Danone memes_5lmocm.jpg', 'Danone memes_5b1d46878de83.jpeg', 'Danone memes_page_1.webp'], \"kellogg's\": ['Kelloggs memes_Image_3.jpeg', 'Kelloggs memes_Image_3.jpg'], 'linkedin': ['LinkedIn memes_Image_2.jpg'], 'corona': ['Corona memes_om9ysstu92k41.jpg'], 'fedex': ['FedEx memes_Image_1.jpg', 'FedEx memes_Image_5.jpg', 'FedEx memes_Image_2.jpeg', 'FedEx memes_Image_3.jpg'], 'caterpillar': ['Caterpillar memes_image-1.webp'], 'dhl': ['DHL memes_Image_5.jpg', 'DHL memes_Image_4.png', 'DHL memes_Image_1.jpg', 'DHL memes_Image_2.jpeg'], \"jack daniel's\": ['JackDaniels memes_Image_4.jpg'], 'prada': ['Prada memes_highxtar-prada-ss21-campaign-4.jpg', 'Prada memes_highxtar-prada-ss21-campaign-1.jpg', 'Prada memes_DIETPRADA3.webp', 'Prada memes_highxtar-prada-ss21-campaign-2.jpg'], 'xiaomi': ['Xiaomi memes_9daf00f7-8607-4ff6-b8e1-1dd5c755f43a.jpeg', 'Xiaomi memes_Image_4.jpeg', 'Xiaomi memes_Image_1.jpeg'], 'kia': [], 'tiffany & co.': [], 'panasonic': ['Panasonic memes_Image_5.jpg', 'Panasonic memes_Image_4.jpeg', 'Panasonic memes_Image_1.jpeg'], 'hewlett packard enterprise': ['hp enterprise', 'hewlett packard', 'HewlettPackardEnterprise memes_maxresdefault.jpg', 'HewlettPackardEnterprise memes_EPo6d7mUYAAHsU0.jpg'], 'huawei': ['Huawei memes_Image_5.jpg', 'Huawei memes_u8978vigrj031.webp', 'Huawei memes_Image_3.jpg'], 'hennessy': ['Hennessy memes_Image_4.jpg', 'Hennessy memes_Image_3.jpg', 'Hennessy memes_Image_2.jpg', 'Hennessy memes_Image_1.jpg', 'Hennessy memes_Image_5.jpg'], 'burberry': ['Burberry memes_images.jpeg', 'Burberry memes_Image_3.jpg', 'Burberry memes_4febf2b9add2cf73f8e3bcca6f67c904.jpg', 'Burberry memes_Image_5.jpg'], 'kfc': ['KFC memes_Image_4.jpg', 'KFC memes_Image_1.jpeg', 'KFC memes_Image_5.jpeg', 'KFC memes_Image_2 (copy 1).jpg'], 'johnson & johnson': ['JohnsonJohnson memes_jj-vaccine-covid-19-vaccine-memes-covid-19-memes-funny-memes-memes-twitter-memes-funny-tweets.jpeg', 'JohnsonJohnson memes_memes-for-use-to-spam-j-j-v0-2kmhfpfrrmbb1.webp', 'JohnsonJohnson memes_Image_1.jpg'], 'sephora': ['Sephora memes_Image_5.png', 'Sephora memes_Image_2.jpg', 'Sephora memes_Image_1.jpg', 'Sephora memes_Image_4.jpeg', 'Sephora memes_Image_3.jpg'], 'nespresso': ['Nespresso memes_Image_3.jpg', 'Nespresso memes_Image_1.jpg', 'Nespresso memes_Image_2.jpg', 'Nespresso memes_Image_4.jpg', 'Nespresso memes_Image_5.jpg'], 'heineken': ['Corona memes_images.jpeg', 'Heineken memes_Image_1.jpg', 'Heineken memes_Image_5.jpg'], 'canon': ['Canon memes_55bc7be8031ed.jpeg', 'Canon memes_7ugwbf.jpg', 'Canon memes_Image_1.jpg', 'Canon memes_xzgpcaalz69a1.jpg']}\n",
    "result = {}\n",
    "\n",
    "for key in dict1:\n",
    "    if key in dict2:\n",
    "        if key not in result:\n",
    "            result[key] = dict1[key] + dict2[key]\n",
    "    else:\n",
    "        result[key] = dict1[key]\n",
    "\n",
    "for key in dict2:\n",
    "    if key not in result:\n",
    "        result[key] = dict2[key]\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T18:40:28.317Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i, (key, value_list) in enumerate(dict1.items()):\n",
    "    print(f\"{i} \\t {key}: {value_list}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T18:40:28.317Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dagsub connection, authentication"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T13:47:12.279017Z",
     "iopub.status.busy": "2024-05-22T13:47:12.278664Z",
     "iopub.status.idle": "2024-05-22T13:47:25.888728Z",
     "shell.execute_reply": "2024-05-22T13:47:25.887436Z",
     "shell.execute_reply.started": "2024-05-22T13:47:12.278987Z"
    }
   },
   "source": [
    "!pip install -U mlflow>=1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T08:52:19.316018Z",
     "iopub.status.busy": "2025-01-03T08:52:19.315751Z",
     "iopub.status.idle": "2025-01-03T08:52:22.745874Z",
     "shell.execute_reply": "2025-01-03T08:52:22.745053Z",
     "shell.execute_reply.started": "2025-01-03T08:52:19.315983Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!rm -r /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T18:40:28.317Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!rm -fr /kaggle/working/DIRPATH/model-epoch=14-val_loss=1.60.ckpt"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5366753,
     "sourceId": 8922601,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5717524,
     "sourceId": 10364389,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6031274,
     "sourceId": 10364801,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 90746,
     "modelInstanceId": 65899,
     "sourceId": 78408,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 231646,
     "modelInstanceId": 209951,
     "sourceId": 245713,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
